{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vqa_test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hK3wsDDllEik","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612087953824,"user_tz":-60,"elapsed":104656,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"5b8ca9ad-d62c-4db8-c308-3ec87848ae32"},"source":["from IPython.core.interactiveshell import InteractiveShell\r\n","InteractiveShell.ast_node_interactivity = \"all\"\r\n","!pip install tensorflow==2.1.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.32.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.19.5)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 50.6MB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 51.8MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.36.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (51.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=02e61d88214e53f02ba73fdbf846b7084439cd5860ad8f5b7eb92381d9729881\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, gast, tensorflow\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"A8PuF_qVTNq4","executionInfo":{"status":"ok","timestamp":1612087955284,"user_tz":-60,"elapsed":105998,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"e0e5f8e5-d500-4b45-8c95-ffb1f5e36b77"},"source":["import tensorflow as tf \r\n","tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.1.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SmrvY8XomcSa","executionInfo":{"status":"ok","timestamp":1612087955285,"user_tz":-60,"elapsed":105996,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["import os\r\n","#import tensorflow as tf\r\n","from tensorflow.keras.callbacks import TensorBoard\r\n","from tensorflow.keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU, add, Conv2D, Reshape\r\n","from tensorflow.keras.callbacks import Callback\r\n","from tensorflow.keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\r\n","from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D, multiply\r\n","from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\r\n","from tensorflow.keras.callbacks import LearningRateScheduler\r\n","from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\r\n","from tensorflow.keras.models import Model\r\n","from tensorflow.keras.metrics import CategoricalAccuracy\r\n","from tensorflow.keras.optimizers import Adam\r\n","from tensorflow.keras.applications import VGG16, VGG19\r\n","from tensorflow.keras.applications.vgg19 import preprocess_input\r\n","from tensorflow.keras.utils import Sequence\r\n","from tensorflow.keras import utils\r\n","from tensorflow.keras.utils import plot_model\r\n","from tensorflow.keras.preprocessing import image, text, sequence\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras.layers import Layer\r\n","from tensorflow.keras import backend as K\r\n","\r\n","\r\n","\r\n","import numpy as np\r\n","\r\n","SEED = 1234\r\n","np.random.seed(SEED)\r\n","tf.random.set_seed(SEED)  \r\n","\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"llAVX2V9mcd0","executionInfo":{"status":"ok","timestamp":1612087957297,"user_tz":-60,"elapsed":54100,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["from os import listdir, makedirs\r\n","from os.path import isfile, join, basename, splitext\r\n","from random import seed, shuffle\r\n","import glob\r\n","import time\r\n","# set the matplotlib backend so figures can be saved in the background\r\n","import matplotlib\r\n","import matplotlib.pyplot as plt\r\n","matplotlib.use(\"Agg\")\r\n","# import the necessary packages\r\n","\r\n","from sklearn.model_selection import StratifiedShuffleSplit\r\n","from sklearn.utils.class_weight import compute_class_weight\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.metrics import accuracy_score, f1_score\r\n","from sklearn import preprocessing\r\n","from sklearn.metrics import classification_report\r\n","\r\n","from imutils import paths\r\n","import math\r\n","import numpy as np\r\n","import pickle\r\n","import operator\r\n","from operator import itemgetter\r\n","from itertools import zip_longest\r\n","from collections import defaultdict\r\n","import json\r\n","import joblib\r\n","from tqdm import tqdm\r\n","import pandas as pd\r\n","from nltk.tokenize.treebank import TreebankWordTokenizer\r\n","import pandas as pd\r\n","import seaborn as sns\r\n","import datetime"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NI7y6s_rm229","executionInfo":{"status":"ok","timestamp":1612087976203,"user_tz":-60,"elapsed":69530,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"31c96497-69bb-4fba-a4ff-55e0b1fc2cda"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lFYobkfsm8of","executionInfo":{"status":"ok","timestamp":1612088168829,"user_tz":-60,"elapsed":258963,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["%%capture\r\n","!unzip /content/drive/My\\ Drive/anndl-2020-vqa.zip"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xSpVK_H-M8MN","executionInfo":{"status":"ok","timestamp":1612088168831,"user_tz":-60,"elapsed":193281,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["from os import listdir, makedirs\r\n","from os.path import isfile, join, basename, splitext\r\n","from random import seed, shuffle\r\n","from PIL import Image\r\n","import json\r\n","import cv2\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","\r\n","imgs_path = '/content/VQA_Dataset/Images'\r\n","train_json_path = '/content/VQA_Dataset/train_questions_annotations.json'\r\n","test_json_path = '/content/VQA_Dataset/test_questions.json'\r\n","  \r\n","DATASET_SPLIT = 0.8\r\n","BATCH_SIZE = 128\r\n","  \r\n","classes = {'0': 0,\r\n","            '1': 1,\r\n","            '2': 2,\r\n","            '3': 3,\r\n","            '4': 4,\r\n","            '5': 5,\r\n","            'apple': 6,\r\n","            'baseball': 7,\r\n","            'bench': 8,\r\n","            'bike': 9,\r\n","            'bird': 10,\r\n","            'black': 11,\r\n","            'blanket': 12,\r\n","            'blue': 13,\r\n","            'bone': 14,\r\n","            'book': 15,\r\n","            'boy': 16,\r\n","            'brown': 17,\r\n","            'cat': 18,\r\n","            'chair': 19,\r\n","            'couch': 20,\r\n","            'dog': 21,\r\n","            'floor': 22,\r\n","            'food': 23,\r\n","            'football': 24,\r\n","            'girl': 25,\r\n","            'grass': 26,\r\n","            'gray': 27,\r\n","            'green': 28,\r\n","            'left': 29,\r\n","            'log': 30,\r\n","            'man': 31,\r\n","            'monkey bars': 32,\r\n","            'no': 33,\r\n","            'nothing': 34,\r\n","            'orange': 35,\r\n","            'pie': 36,\r\n","            'plant': 37,\r\n","            'playing': 38,\r\n","            'red': 39,\r\n","            'right': 40,\r\n","            'rug': 41,\r\n","            'sandbox': 42,\r\n","            'sitting': 43,\r\n","            'sleeping': 44,\r\n","            'soccer': 45,\r\n","            'squirrel': 46,\r\n","            'standing': 47,\r\n","            'stool': 48,\r\n","            'sunny': 49,\r\n","            'table': 50,\r\n","            'tree': 51,\r\n","            'watermelon': 52,\r\n","            'white': 53,\r\n","            'wine': 54,\r\n","            'woman': 55,\r\n","            'yellow': 56,\r\n","            'yes': 57}\r\n","  \r\n","N_CLASSES = len(classes)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4VBgN6vQxT_"},"source":["def image_feature_extractor(target_path, image_list, BATCH_SIZE):\r\n","\t\"\"\"\r\n","\tExtracts (512, 7, 7)-dimensional CNN features and save them locally\r\n","\r\n","\tInput:\r\n","\t\ttarget_path: path to save the features\r\n","\t\timage_list: image filenames\r\n","\t\tBATCH_SIZE: batch size\r\n","\r\n","\tReturns:\r\n","\t\tNone\r\n","\t\"\"\"\r\n","\t \r\n","\tmodel = VGG19(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(3, 224, 224)))\r\n","\r\n","  \t# add a progress bar\r\n","\tprogbar = utils.Progbar(int(np.ceil(len(image_list) / float(BATCH_SIZE))))\r\n","\r\n","  \t# loop over the images in batches\r\n","\tfor (b, i) in enumerate(range(0, len(image_list), BATCH_SIZE)):\r\n","\t\t# extract batch of images and prepare them to pass it through the VGG \r\n","\t\t# network for feature extraction\r\n","\r\n","\t\tprogbar.update(b+1)\r\n","\t\t\r\n","\t\tbatch_range = range(i, min(i + BATCH_SIZE, len(image_list)))\r\n","\t\tbatchPaths = image_list[batch_range[0]: batch_range[-1]+1]\r\n","\r\n","\t\tbatchImages = []\r\n","\t\tbatchIds = []\r\n","\t\t# loop over the images and labels in the current batch\r\n","\t\tfor imagePath in batchPaths:\r\n","\r\n","            # load the input image using the Keras helper utility\r\n","            # while ensuring the image is resized to 224x224 pixels\r\n","\t\t\timg = image.load_img(os.path.join(imgs_path,imagePath), target_size=(224, 224))\r\n","\t\t\timg = image.img_to_array(img)\r\n","    \r\n","            # preprocess the image by \r\n","            # (1) expanding the dimensions to include batch dim and\r\n","            # (2) subtracting the mean RGB pixel intensity from the ImageNet dataset\r\n","\t\t\timg = np.expand_dims(img, axis=0)\r\n","\t\t\timg = preprocess_input(img)\r\n","    \r\n","            # add the image to the batch\r\n","\t\t\tbatchImages.append(img)\r\n","\t\t\t# image ids of the batch\r\n","\t\t\tbatchIds.append(imagePath.split('.')[0][-6:])\r\n","\t  \r\n","\t\tbatchImages = np.vstack(batchImages) # (BATCH_SIZE, 3, 224, 224)\r\n","\r\n","\t\t# pass the images through the network and use the outputs as our actual features\r\n","\t\tfeatures = model.predict(batchImages) # (BATCH_SIZE, 512, 7, 7)\r\n","\t\tfeatures = tf.reshape(features, (features.shape[0], features.shape[1], -1)) # (BATCH_SIZE, 512, 49)\r\n","\t\tfeatures = tf.transpose(features, perm =[0,2,1])  # (BATCH_SIZE, 49, 512)\r\n","\r\n","\t\t# loop over the batch to save them locally\r\n","\t\tfor id, feat in zip(batchIds, features):\r\n","\t\t\tnp.save(os.path.join(target_path, id), feat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbl912KkSLsz"},"source":["image_list = os.listdir(\"/content/VQA_Dataset/Images\")\r\n","BATCH_SIZE = 128\r\n","target_path = '/content/drive/My Drive/VQA/features'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zl3ThJ6kSU0M","executionInfo":{"status":"ok","timestamp":1612014710109,"user_tz":-60,"elapsed":804194,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"9c6ac8f9-ab58-4b40-c414-d4fb87c766fe"},"source":["image_feature_extractor(target_path, image_list, BATCH_SIZE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["98/98 [==============================] - 794s 8s/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"02QIzaKv4a6_","executionInfo":{"status":"ok","timestamp":1612088169742,"user_tz":-60,"elapsed":897,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["from tensorflow.keras.applications.vgg19 import preprocess_input\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","\r\n","\r\n","def process_sentence(sentence):\r\n","    \"\"\"\r\n","    Cleans a given raw sentence\r\n","    Input:\r\n","        sentence: a raw sentence\r\n","    Returns:\r\n","        Returns the cleaned version of the sentence\r\n","    \"\"\"\r\n","    # remove the character \".\", except from floating numbers\r\n","    periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\r\n","    # remove any \",\" between digits, eg: 5,6\r\n","    commaStrip   = re.compile(\"(\\d)(\\,)(\\d)\")\r\n","    # list of punctuations to remove\r\n","    punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\r\n","                    '(', ')', '=', '+', '\\\\', '_', '-',\r\n","                    '*', ':', '^', '%', '$', '#', '&',\r\n","                    '>', '<', '@', '`', ',', '?', '!']\r\n","    # contraction mappings\r\n","    contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\", \\\r\n","                    \"couldn'tve\": \"couldn't've\", \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\": \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \\\r\n","                    \"hadnt've\": \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\": \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \\\r\n","                    \"he'dve\": \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\", \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\", \\\r\n","                    \"Im\": \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\": \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\", \\\r\n","                    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\": \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\", \\\r\n","                    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\", \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\", \\\r\n","                    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\": \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\": \"she'd've\", \\\r\n","                    \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\": \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\": \"shouldn't've\", \\\r\n","                    \"somebody'd\": \"somebodyd\", \"somebodyd've\": \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\": \"somebody'll\", \\\r\n","                    \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\", \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\", \\\r\n","                    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\": \"something'd\", \"somethingd've\": \"something'd've\", \\\r\n","                    \"something'dve\": \"something'd've\", \"somethingll\": \"something'll\", \"thats\": \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\", \\\r\n","                    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\": \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \\\r\n","                    \"they'dve\": \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\": \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \\\r\n","                    \"wed've\": \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\": \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \\\r\n","                    \"whats\": \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\": \"where'd\", \"where's\": \"where is\", \"whereve\": \"where've\", \\\r\n","                    \"whod\": \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\": \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\", \\\r\n","                    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\": \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\", \\\r\n","                    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\": \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\", \\\r\n","                    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\": \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \\\r\n","                    \"youll\": \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"}\r\n","\r\n","    # replace new line with a white space\r\n","    inText = sentence.replace('\\n', ' ')\r\n","    # replace multiple white space with single white space\r\n","    inText = inText.replace('\\t', ' ')\r\n","    inText = inText.strip()\r\n","    outText = inText\r\n","    for p in punct:\r\n","        if (p + ' ' in inText or ' ' + p in inText) or \\\r\n","           (re.search(commaStrip, inText) != None):\r\n","            outText = outText.replace(p, '')\r\n","        else:\r\n","            outText = outText.replace(p, ' ')\r\n","    outText = periodStrip.sub(\"\", outText, re.UNICODE)\r\n","    outText = outText.lower().split()\r\n","    for wordId, word in enumerate(outText):\r\n","        if word in contractions:\r\n","            outText[wordId] = contractions[word]\r\n","    outText = ' '.join(outText)\r\n","    return outText\r\n","\r\n","\r\n","\r\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyJgzHYaNeWa","executionInfo":{"status":"ok","timestamp":1612088170132,"user_tz":-60,"elapsed":1282,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["#read train JSON file\r\n","with open(train_json_path, 'r') as f:\r\n","    train_data = json.load(f)\r\n","f.close()\r\n","\r\n","#read test JSON file\r\n","with open(test_json_path, 'r') as f:\r\n","    test_data = json.load(f)\r\n","f.close()\r\n","\r\n","\r\n","TOT_QUESTIONS = len(train_data)\r\n","indx = list(train_data.keys())\r\n","train_indx = indx[:int(TOT_QUESTIONS*DATASET_SPLIT)]\r\n","valid_indx = indx[int(TOT_QUESTIONS*DATASET_SPLIT):]\r\n","\r\n","\r\n","\r\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceVPR1yt8ZLP","executionInfo":{"status":"ok","timestamp":1612091640834,"user_tz":-60,"elapsed":631,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["\r\n","class DataGenerator(tf.keras.utils.Sequence):\r\n","    \r\n","    def __init__(self, list_IDs, image_path, train_input_questions, max_length,to_fit=True,\r\n","                 batch_size=128, dim=(49, 512), n_channels=3, n_classes=N_CLASSES, shuffle=True):\r\n","        self.list_IDs = list_IDs\r\n","        self.train_input_questions = train_input_questions\r\n","        self.image_path = image_path\r\n","        self.batch_size = batch_size\r\n","        self.dim = dim\r\n","        self.n_channels = n_channels\r\n","        self.n_classes = n_classes\r\n","        self.shuffle = shuffle\r\n","        self.to_fit=to_fit\r\n","        self.max_length = max_length\r\n","        self.on_epoch_end()\r\n","\r\n","    def __len__(self):\r\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\r\n","\r\n","    def __getitem__(self, index):\r\n","        # Generate indexes of the batch\r\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\r\n","\r\n","        # Find list of IDs\r\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\r\n","\r\n","        # Generate data\r\n","        X = self._generate_X(list_IDs_temp)\r\n","\r\n","        if self.to_fit:\r\n","            y = self._generate_y(list_IDs_temp)\r\n","            return X, y\r\n","        else:\r\n","            return X\r\n","\r\n","    def on_epoch_end(self):\r\n","        self.indexes = np.arange(len(self.list_IDs))\r\n","        if self.shuffle == True:\r\n","            np.random.shuffle(self.indexes)\r\n","\r\n","    def _generate_X(self, list_IDs_temp):\r\n","        # Initialization\r\n","        X = np.empty((self.batch_size, *self.dim))\r\n","        X2 = np.empty((self.batch_size, self.max_length))\r\n","\r\n","        # Generate data\r\n","        for i, ID in enumerate(list_IDs_temp):\r\n","            # Store sample\r\n","            X[i,] = self._load_image(self.image_path[i])\r\n","            X2[i,] = (self.train_input_questions[i]).tolist()\r\n","        ole = [X2, X]\r\n","        \r\n","        return ole\r\n","\r\n","    def _generate_y(self, list_IDs_temp):\r\n","        y = np.empty((self.batch_size, 1), dtype=int)\r\n","\r\n","        # Generate data\r\n","        for i, ID in enumerate(list_IDs_temp):\r\n","            # Store sample\r\n","            y[i] = self.list_IDs[ID]\r\n","\r\n","        return y\r\n","\r\n","#Qua in origine c'era la divisione tra immagine training set o test set ma nel nostro dataset c'è\r\n","#un unico insieme di immagini, non so se valga la pena unire togliendo l'if\r\n","    def _load_image(self, image_path):\r\n","        image = np.load('/content/drive/MyDrive/VQA/features/' + image_path.split('.')[0][-6:] + '.npy')  \r\n","        return image"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"id":"wICJX9kl8cm4","executionInfo":{"status":"ok","timestamp":1612091398728,"user_tz":-60,"elapsed":450,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["MAX_LEN = 22\r\n","\r\n","def readTrainJson(data, first, last):\r\n","        images = []\r\n","        questions = []\r\n","        answers = []\r\n","\r\n","        #Questo fa schifo è da cambiare\r\n","        count = first\r\n","\r\n","        for question in data:\r\n","            if count < first:\r\n","              continue\r\n","            if count >= last:\r\n","              break\r\n","            q = data[question]\r\n","            name = q['image_id']\r\n","            quest = process_sentence(q['question'])\r\n","            ans = q['answer']\r\n","            images.append(name)\r\n","            questions.append(quest)\r\n","            answers.append(classes[ans])\r\n","            count += 1\r\n","        return images, questions, answers\r\n","\r\n","def readTestJson(data, first, last):\r\n","    quest_id = []\r\n","    images = []\r\n","    questions = []\r\n","\r\n","\r\n","    for question in data:\r\n","        q = data[question]\r\n","        qid = question\r\n","        name = q['image_id']\r\n","        quest = process_sentence(q['question'])\r\n","        quest_id.append(int(qid))\r\n","        images.append(name)\r\n","        questions.append(quest)\r\n","    return images, questions, quest_id"],"execution_count":112,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYG4Kxsb8duD","executionInfo":{"status":"ok","timestamp":1612091690933,"user_tz":-60,"elapsed":4992,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["#read train JSON file\r\n","with open(train_json_path, 'r') as f:\r\n","    train_data = json.load(f)\r\n","f.close()\r\n","\r\n","#read test JSON file\r\n","with open(test_json_path, 'r') as f:\r\n","    test_data = json.load(f)\r\n","f.close()\r\n","\r\n","img_h=49\r\n","img_w=512\r\n","TOT_QUESTIONS = len(train_data)\r\n","TRAIN_QUESTIONS = int(TOT_QUESTIONS*DATASET_SPLIT)\r\n","VALID_QUESTIONS = TOT_QUESTIONS-TRAIN_QUESTIONS\r\n","\r\n","#extract images, questions and answer (or quest_id) from the train and test files\r\n","train_images, train_questions, train_answers = readTrainJson(train_data, 0, TRAIN_QUESTIONS)\r\n","valid_images, valid_questions, valid_answers = readTrainJson(train_data, TRAIN_QUESTIONS, TOT_QUESTIONS)\r\n","test_images, test_questions, questions_id = readTestJson(test_data, 0, len(test_data))\r\n","\r\n","sequences = tokenizer.texts_to_sequences(train_questions)\r\n","train_input_questions = pad_sequences(sequences, maxlen=MAX_LEN)\r\n","\r\n","sequences = tokenizer.texts_to_sequences(valid_questions)\r\n","valid_input_questions = pad_sequences(sequences, maxlen=MAX_LEN)\r\n","\r\n","\r\n","sequences = tokenizer.texts_to_sequences(test_questions)\r\n","test_input_questions = pad_sequences(sequences, maxlen=MAX_LEN)\r\n","words_number = len(tokenizer.word_index) + 1\r\n","\r\n","training_generator = DataGenerator(train_answers, train_images, train_input_questions, MAX_LEN, batch_size=BATCH_SIZE, dim=(img_h, img_w), n_classes=N_CLASSES)\r\n","validation_generator = DataGenerator(valid_answers, valid_images, valid_input_questions, MAX_LEN, batch_size=BATCH_SIZE, dim=(img_h, img_w), n_classes=N_CLASSES)\r\n","test_generator = DataGenerator(questions_id, test_images, test_input_questions, MAX_LEN,to_fit=False, batch_size=1, dim=(img_h, img_w), n_classes=N_CLASSES, shuffle=False)"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hgqoJcS_88H","executionInfo":{"status":"ok","timestamp":1612091704534,"user_tz":-60,"elapsed":520,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["def build_model(max_answers, max_seq_len, vocab_size, dim_d, dim_k, l_rate, d_rate, reg_value):\r\n","    \"\"\"\r\n","    Defines the Keras model.\r\n","\r\n","    Arguments\r\n","    ----------\r\n","    max_answers : Number of output targets of the model.\r\n","    max_seq_len : Length of input sequences\r\n","    vocab_size  : Size of the vocabulary, i.e. maximum integer index + 1.\r\n","    dim_d       : Hidden dimension\r\n","    dim_k       : Hidden attention dimension\r\n","    l_rate      : Learning rate for the model\r\n","    d_rate      : Dropout rate\r\n","    reg_value   : Regularization value\r\n","\r\n","    Returns\r\n","    ----------\r\n","    Returns the Keras model.\r\n","    \"\"\"\r\n","    # inputs \r\n","    image_input = Input(shape=(49, 512), name='Image_Input')\r\n","    ques_input = Input(shape=(22, ), name='Question_Input')\r\n","\r\n","    # image feature;\r\n","    img_model = tf.keras.models.Sequential()\r\n","    img_model.add(Flatten())\r\n","    img_model.add(Dense(dim_d, activation='relu', \\\r\n","                    kernel_regularizer=tf.keras.regularizers.l2(reg_value),\\\r\n","                        kernel_initializer=tf.keras.initializers.glorot_uniform(seed=13)))\r\n","    encoded_image = img_model(image_input)\r\n","    # question feature;\r\n","    word_model = tf.keras.models.Sequential()\r\n","    word_model.add(Embedding(input_dim=vocab_size, output_dim=dim_d, input_length=max_seq_len,\\\r\n","                            mask_zero=True))\r\n","    word_model.add(LSTM(units=512, return_sequences=True))\r\n","    word_model.add(Dropout(d_rate))\r\n","    word_model.add(LSTM(units=512, return_sequences=False))\r\n","    word_model.add(Dropout(d_rate))\r\n","    word_model.add(Dense(dim_d, activation='relu', \\\r\n","                    kernel_regularizer=tf.keras.regularizers.l2(reg_value),\\\r\n","                        kernel_initializer=tf.keras.initializers.glorot_uniform(seed=13)))\r\n","    encoded_quest= word_model(ques_input)\r\n","    # result\r\n","    combine = concatenate([encoded_image,encoded_quest])\r\n","    d_layer = Dropout(d_rate)(combine)\r\n","    dense1 = Dense(1000,activation='tanh')(d_layer)\r\n","    d_layer2 =  Dropout(d_rate)(dense1)\r\n","    result = Dense(max_answers, activation='softmax')(d_layer2)\r\n","\r\n","    model = Model(inputs=[ques_input,image_input], outputs=result)\r\n","\r\n","    return model"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTTc4K4h__5Z","executionInfo":{"status":"ok","timestamp":1612091709084,"user_tz":-60,"elapsed":3616,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["# params 1\r\n","\r\n","\r\n","max_seq_len = 22\r\n","vocab_size  = len(tokenizer.word_index) + 1\r\n","dim_d       = 512\r\n","dim_k       = 256\r\n","l_rate      = 1e-4\r\n","d_rate      = 0.5\r\n","reg_value   = 0.01\r\n","# create model\r\n","model = build_model(N_CLASSES, max_seq_len, vocab_size, dim_d, dim_k, l_rate, d_rate, reg_value)"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_cYf3WEAlh-","executionInfo":{"status":"ok","timestamp":1612091709086,"user_tz":-60,"elapsed":3101,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["   # Loss\r\n","loss = tf.keras.losses.SparseCategoricalCrossentropy()\r\n","\r\n","# learning rate\r\n","lr = 5e-4\r\n","#optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n","optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr, rho=0.9)\r\n","# -------------------\r\n","\r\n","# Validation metrics\r\n","# ------------------\r\n","\r\n","metrics = ['accuracy']\r\n","# ------------------\r\n","\r\n","# Compile Model\r\n","#vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHZwIAtUBPRD","executionInfo":{"status":"ok","timestamp":1612091709087,"user_tz":-60,"elapsed":2395,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}}},"source":["# Early Stopping\r\n","# --------------\r\n","callbacks = []\r\n","early_stop = True\r\n","if early_stop:\r\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\r\n","    callbacks.append(es_callback)\r\n","\r\n"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B43E8bwLAqfd","outputId":"b976f10f-8896-4f61-85e5-4603e5314a85"},"source":["model.fit_generator(generator=training_generator,\r\n","                        validation_data=validation_generator,\r\n","                        epochs=60)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 367 steps, validate for 91 steps\n","Epoch 1/60\n","367/367 [==============================] - 98s 266ms/step - loss: 4.7662 - accuracy: 0.5784 - val_loss: 2.6746 - val_accuracy: 0.6383\n","Epoch 2/60\n","323/367 [=========================>....] - ETA: 8s - loss: 2.5389 - accuracy: 0.6272"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SLBSSErBPszU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612076474618,"user_tz":-60,"elapsed":834,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"bee11a39-8077-4207-c1ec-b33bd484c630"},"source":["pred = model.predict_generator(test_generator)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['cat', 'cat', 'cat', ..., 'cat', 'cat', 'cat'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"tcoedQR9Nsg6","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1612076028239,"user_tz":-60,"elapsed":4444,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"572143c0-bb7c-4ef5-fbc0-2a1e4e69789d"},"source":["\r\n","import os\r\n","from datetime import datetime\r\n","from google.colab import files\r\n","\r\n","def create_csv(results, results_dir='./'):\r\n","\r\n","    csv_fname = 'results_'\r\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\r\n","\r\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\r\n","\r\n","        f.write('Id,Category\\n')\r\n","\r\n","        for key, value in results.items():\r\n","            f.write(str(key) + ',' + str(value) + '\\n')\r\n","    \r\n","    return csv_fname\r\n","\r\n","results = {}\r\n","\r\n","for i in range(len(pred)):\r\n","    results[test_generator.list_IDs[i]] = np.argmax(pred[i])\r\n","\r\n","name = create_csv(results)\r\n","\r\n","files.download(name)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_9b5f8f90-3429-4a52-b2d5-6bdb872ab966\", \"results_Jan31_06-53-46.csv\", 61350)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SksWUrZuAnSF","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1612012569053,"user_tz":-60,"elapsed":639,"user":{"displayName":"Edoardo Putti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7oizfBqgR_sAV-NMtKUxel-6CGnUb_8hqENyzJA=s64","userId":"10533665133871308250"}},"outputId":"23635f60-598c-4a18-b09d-e326f008ca64"},"source":[""],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_1d13ca18-acbd-476d-9bc1-ac23299698e9\", \"\", 815104)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"d1TwE1nEbx79"},"source":[""],"execution_count":null,"outputs":[]}]}