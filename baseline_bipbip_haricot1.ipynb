{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                      width_shift_range=10,\n",
    "                                      height_shift_range=10,\n",
    "                                      zoom_range=0.3,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "    mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                       width_shift_range=10,\n",
    "                                       height_shift_range=10,\n",
    "                                       zoom_range=0.3,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='reflect')\n",
    "else:\n",
    "    img_data_gen = ImageDataGenerator()\n",
    "    mask_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from read_mask_example import read_rgb_mask\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "  \"\"\"\n",
    "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
    "\n",
    "    3 main methods:\n",
    "      - __init__: save dataset params like directory, filenames..\n",
    "      - __len__: return the total number of samples in the dataset\n",
    "      - __getitem__: return a sample from the dataset\n",
    "\n",
    "    Note: \n",
    "      - the custom dataset return a single sample from the dataset. Then, we use \n",
    "        a tf.data.Dataset object to group samples into batches.\n",
    "      - in this case we have a different structure of the dataset in memory. \n",
    "        We have all the images in the same folder and the training and validation splits\n",
    "        are defined in text files.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[256, 256]):\n",
    "    if which_subset == 'training':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
    "    elif which_subset == 'validation':\n",
    "      subset_file = os.path.join(dataset_dir, 'Splits', 'valid.txt')\n",
    "    \n",
    "    with open(subset_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "    \n",
    "    subset_filenames = []\n",
    "    for line in lines:\n",
    "      subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # Read Image\n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    img = Image.open(os.path.join(self.dataset_dir, 'Images/', curr_filename + '.jpg'))\n",
    "    mask = Image.fromarray(read_rgb_mask(os.path.join(self.dataset_dir, 'Masks/', curr_filename + '.png')))\n",
    "\n",
    "    # Resize image and mask\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    # in this dataset 255 mask label is assigned to an additional class, which corresponds \n",
    "    # to the contours of the objects. We remove it for simplicity.\n",
    "    #mask_arr[mask_arr == 255] = 0\n",
    "\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "\n",
    "    if self.which_subset == 'training':\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        # Perform data augmentation\n",
    "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
    "        # and we can apply it to the image using apply_transform\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
    "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
    "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
    "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
    "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
    "            # from [0, 1] to {0, 1}\n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            # recover original class\n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "    return img_arr, np.float32(out_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes = 3\n",
    "dataset_dir = 'D:/OneDrive - Politecnico di Milano/Corsi/2 Anno - 1 Sem/Artificial Neural Networks and Deep Learning/Homework/NNDL/Development_Dataset/Training/Bipbip/Haricot/'\n",
    "\n",
    "\n",
    "# Set preprocess_input = None to display original image\n",
    "dataset = CustomDataset(dataset_dir, 'training', \n",
    "                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
    "                        preprocessing_function=preprocess_input)\n",
    "dataset_valid = CustomDataset(dataset_dir, 'validation', \n",
    "                              preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8 # batch size\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(bs)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.batch(bs)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test data generator\n",
    "# -------------------------\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Assign a color to each class\n",
    "evenly_spaced_interval = np.linspace(0, 1, num_classes)\n",
    "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "\n",
    "iterator = iter(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]   # First element\n",
    "augmented_img = augmented_img  # denormalize\n",
    "\n",
    "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
    "\n",
    "print(np.unique(target))\n",
    "\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "for i in range(1, num_classes + 1):\n",
    "  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
    "\n",
    "ax[0].imshow(np.uint8(augmented_img))\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "\n",
    "finetuning = False\n",
    "\n",
    "if finetuning:\n",
    "    freeze_until = 15 # layer from which we want to fine-tune\n",
    "    \n",
    "    for layer in encoder.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    encoder.trainable = False\n",
    "    for layer in encoder.layers:\n",
    "        encoder.trainable = False\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(depth, start_f, num_classes):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    model.add(encoder)\n",
    "    \n",
    "    start_f = 256\n",
    "        \n",
    "    # Decoder\n",
    "    for i in range(depth):\n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same'))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
    "                                     kernel_size=(1, 1),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "model = create_model(depth=5, start_f=8, num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "\n",
    "# Loss\n",
    "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Here we define the intersection over union for each class in the batch.\n",
    "# Then we compute the final iou as the mean over classes\n",
    "def meanIoU(y_true, y_pred):\n",
    "    # get predicted class from softmax\n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(1, num_classes + 1): # exclude the background class 0\n",
    "      # Get prediction and target related to only a single class (i)\n",
    "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "      intersection = tf.reduce_sum(class_true * class_pred)\n",
    "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "    \n",
    "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "      per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "# Validation metrics\n",
    "metrics = ['accuracy', meanIoU]\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = []\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=50,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(dataset),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline_bipbip_haricot50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_baseline_bipbip_haricot1', {'meanIoU': meanIoU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, basename, splitext\n",
    "\n",
    "# CustomTestDataset to load test images\n",
    "# Specify the full path to the folder containing the images\n",
    "class CustomTestDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, dataset_dir, img_generator=None, \n",
    "              preprocessing_function=None, out_shape=[256, 256]):\n",
    "\n",
    "      subset_filenames = [splitext(basename(f))[0] for f in \n",
    "                                                listdir(dataset_dir) if isfile(join(dataset_dir, f))]\n",
    "\n",
    "      self.dataset_dir = dataset_dir\n",
    "      self.subset_filenames = subset_filenames\n",
    "      self.img_generator = img_generator\n",
    "      self.preprocessing_function = preprocessing_function\n",
    "      self.out_shape = out_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Read Image\n",
    "        curr_filename = self.subset_filenames[index]\n",
    "        img = Image.open(os.path.join(self.dataset_dir, curr_filename + '.jpg'))\n",
    "\n",
    "        # Resize image and mask\n",
    "        img = img.resize(self.out_shape)\n",
    "\n",
    "        img_arr = np.array(img)\n",
    "\n",
    "        if self.preprocessing_function is not None:\n",
    "            img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "        return img_arr\n",
    "\n",
    "    def get_name(self, index):\n",
    "        return self.subset_filenames[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_submission import rle_encode\n",
    "import json\n",
    "\n",
    "test_dir = 'D:/OneDrive - Politecnico di Milano/Corsi/2 Anno - 1 Sem/Artificial Neural Networks and Deep Learning/Homework/NNDL/Development_Dataset/Test_Dev/Bipbip/Haricot/Images'\n",
    "\n",
    "test_dataset = CustomTestDataset(test_dir, preprocessing_function=preprocess_input)\n",
    "\n",
    "submission_dict = {}\n",
    "\n",
    "for i in range(test_dataset.__len__()):\n",
    "    image = test_dataset.__getitem__(i)\n",
    "    img_name = test_dataset.get_name(i)\n",
    "\n",
    "    prediction = model.predict(tf.expand_dims(image, axis=0))\n",
    "    mask_arr = tf.argmax(prediction, -1)[0, ...] # (256, 256)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "\n",
    "    submission_dict[img_name] = {}\n",
    "    submission_dict[img_name]['shape'] = mask_arr.shape\n",
    "    submission_dict[img_name]['team'] = 'Bipbip'\n",
    "    submission_dict[img_name]['crop'] = 'Haricot'\n",
    "    submission_dict[img_name]['segmentation'] = {}\n",
    "\n",
    "    rle_encoded_crop = rle_encode(mask_arr == 1)\n",
    "    rle_encoded_weed = rle_encode(mask_arr == 2)\n",
    "\n",
    "    submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
    "    submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty submission for other datasets\n",
    "def empty_submission(team, crop, dir):\n",
    "    images_dir = join(dir, team, crop, 'Images')\n",
    "    images_name = [splitext(basename(f))[0] for f in listdir(images_dir) if isfile(join(images_dir, f))]\n",
    "    \n",
    "    res = {}\n",
    "    for img_name in images_name:\n",
    "        res[img_name] = {}\n",
    "        res[img_name]['shape'] = [256, 256]\n",
    "        res[img_name]['team'] = team\n",
    "        res[img_name]['crop'] = crop\n",
    "        res[img_name]['segmentation'] = {} \n",
    "        res[img_name]['segmentation']['crop'] = \"\"\n",
    "        res[img_name]['segmentation']['weed'] = \"\"\n",
    "\n",
    "    return res\n",
    "\n",
    "dir = r'D:\\OneDrive - Politecnico di Milano\\Corsi\\2 Anno - 1 Sem\\Artificial Neural Networks and Deep Learning\\Homework\\NNDL\\Development_Dataset\\Test_Dev'\n",
    "submission_dict.update(empty_submission('Bipbip', 'Mais', dir))\n",
    "submission_dict.update(empty_submission('Pead', 'Haricot', dir))\n",
    "submission_dict.update(empty_submission('Pead', 'Mais', dir))\n",
    "submission_dict.update(empty_submission('Roseau', 'Haricot', dir))\n",
    "submission_dict.update(empty_submission('Roseau', 'Mais', dir))\n",
    "submission_dict.update(empty_submission('Weedelec', 'Haricot', dir))\n",
    "submission_dict.update(empty_submission('Weedelec', 'Mais', dir))\n",
    "\n",
    "with open('./submission.json', 'w') as f:\n",
    "    json.dump(submission_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}